import json
import numpy as np

import pyvista as pv
import numpy.linalg as linalg

from scipy.spatial.transform import Rotation as R
from dreifus.camera import CameraCoordinateConvention, PoseType
from dreifus.pyvista import add_floor, add_coordinate_axes, \
    add_camera_frustum, add_coordinate_system, \
    Pose, Intrinsics

# Matrix to convert extrinsic matrix from OpenCV convention to OpenGL convention
# Use:
#   extrinsics_in_GL_format = extrinsics_in_CV_format.dot(CVtoGL)
CVtoGL = np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])

# Matrix used to convert extrinsics matrix from OpenGL convention to OpenCV convention
# Use:
#   extrinsics_in_CV_format = extrinsics_in_GL_format.dot(GLtoCV)
GLtoCV = np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])


def read_transformation_npy(
        extPath: str,
        intPath: str):
    """
        Read in extrinsics/intrinsics from .npy file (as provided).
        The camera coordinate convention is OpenCV

        Parameters
        ---------
            extPath -   Path to extrinsics .npy file
            intPath -   Path to intrinsics .npy file

        Returns
        -------
            Tuple (e,i) of numpy tensors where e represents extrinsics, i represents intrinsics.
            Each tensor has shape (I, 4, 4) [extrinsics]/ (I, 3, 3) [intrinsics] where I is the number of images.
    """

    extr = np.load(extPath, allow_pickle=True)[()]
    intr = np.load(intPath, allow_pickle=True)[()]
    extrinsics = []
    intrinsics = []
    for key in extr:
        extrinsics.append(extr[key])
        intrinsics.append(intr[key])

    eTensor = np.stack(extrinsics, axis=0)
    iTensor = np.stack(intrinsics, axis=0)

    return eTensor, iTensor


def read_transformation_nerfstudio(tPath: str):
    """
    Read in transformation information from a transforms.json file generated by nerfstudio.
    This file contains extrinsics/intrinsics from the different cameras.

    Parameters
    ----------
        tPath:  Path to the transforms.json file (including file name)

    Returns
    -------
        Tuple (e,i) of numpy tensors where e represents extrinsics, i represents intrinsics.
        Each tensor has shape (I, 4, 4) [extrinsics]/ (I, 3, 3) [intrinsics] where I is the number of images.
    """
    extrinsics = []
    intrinsics = []

    with open(tPath, 'r') as f:
        data = json.load(f)
        # Intrinsic parameters
        cx: float = data['cx']
        cy: float = data['cy']
        fx: float = data['fl_x']
        fy: float = data['fl_y']

        # Build matrix
        intr_mat = np.array([
            [fx, 0, cx],
            [0, fy, cy],
            [0, 0, 1]
        ], dtype=np.float32)

        for element in data['frames']:
            cam2world = element['transform_matrix']
            extrinsics.append(np.array(cam2world, dtype=np.float32))

            # The JSON format supports only one global inrinsics matrix
            # but plot function requires matrix for each extrinsics so add every time the same matrix
            intrinsics.append(intr_mat)

    eTensor = np.stack(extrinsics, axis=0)
    iTensor = np.stack(intrinsics, axis=0)
    return eTensor, iTensor


def read_transformation_sdfstudio(tPath: str, fName: str):
    """
    Read in transformation information from meta_data.json file used by sdfstudio.

    Parameters
    ----------
        tPath:  Path to meta_data.json

    Returns
    -------
        Tuple (e,i) continaing extrinsics (e) and intrinsics (i)
    """
    tFile = '/'.join([tPath, fName])
    with open(tFile, 'r') as f:
        data = json.load(f)

        extrinsics = []
        intrinsics = []

        for element in data['frames']:
            cam2world = np.array(element['camtoworld'])
            intr = np.array(element['intrinsics'])
            extrinsics.append(cam2world)

            # In case intrinsics is a 4x4 matrix, trim down to 3x3
            if (intr.shape == (4, 4)):
                intr = intr[:3, :3]

            intrinsics.append(intr)

    return (extrinsics, intrinsics)


def read_transformation_custom_data(path: str):
    """
    Read extrinsic and intrinsic information from custom dataset, i.e.
    assumes that .npy files are present.

    Parameters
    ----------
        path:
            Path to the folder containing the extrinsics/intrinsics.npy files

    Returns
    -------
        Tuple (e,i) containing extrinsics (e) and intrinsics (i)
    """

    extr_file = '/'.join([path, 'extrinsics.npy'])
    intr_file = '/'.join([path, 'intrinsics.npy'])

    c2w_matrices = np.load(extr_file, allow_pickle=True)[()]
    intr_matrices = np.load(intr_file, allow_pickle=True)[()]

    extr_list = []
    intr_list = []

    for key in c2w_matrices:
        extr_list.append(c2w_matrices[key])
        intr_list.append(intr_matrices[key])

    return (extr_list, intr_list)


def plot(extrinsics: np.array, intrinsics: np.array,
         near: float = 1.0, far: float = 10.0, aabb_size: float = 1.0,
         camConvention=CameraCoordinateConvention.OPEN_GL) -> None:
    """
    Plot a given set of extrinsic and intrinsic camera parameters.

    Parameters
    ----------
        extrinsics:         Tensor of shape (i,4,4) representing the extrinsics where i is the number of cameras
        intrinsics:         Tensor of shape (i,3,3) representing the intrinsics where i is the number of cameras
        near:               Near clipping value
        far:                Far clipping value
        aabb_size:          Size of AABB
        camConvention:      Convention of camera coordinate system used in cam2world matrices (OpenCV/OpenGL)
    """
    assert extrinsics.shape[0] == intrinsics.shape[0], 'Mismatch in the number of cameras for intrinsics/extrinsics'

    p = pv.Plotter(notebook=False)

    # Floor is (x,z) plane
    add_floor(p, square_size=1.0, max_distance=10, axes=(0, 1))
    add_coordinate_axes(p, scale=1.0, draw_labels=True)

    for idx in range(extrinsics.shape[0]):
        pv_intr = Intrinsics(intrinsics[idx])
        pv_cam2world = Pose(extrinsics[idx, :, :], pose_type=PoseType.CAM_2_WORLD,
                            camera_coordinate_convention=camConvention)

        # Plot near/far clipping values by a point
        camPos = pv_cam2world.get_translation()
        camDir = pv_cam2world.get_look_direction()
        norm = linalg.norm(camDir)
        camDir /= norm
        pointNear = camPos + near * camDir
        pointFar = camPos + far * camDir
        points = np.stack([pointNear[:3], pointFar[:3]])

        # Draw unit AABB box
        aabb = np.array([
            [1, -1, -1], [1, -1, 1],
            [1, -1, -1], [-1, -1, -1],
            [1, -1, 1], [-1, -1, 1],
            [-1, -1, -1], [-1, -1, 1],
            [1, 1, -1], [1, 1, 1],
            [1, 1, -1], [-1, 1, -1],
            [1, 1, 1], [-1, 1, 1],
            [-1, 1, -1], [-1, 1, 1],
            [-1, 1, -1], [-1, -1, -1],
            [1, 1, -1], [1, -1, -1],
            [-1, 1, 1], [-1, -1, 1],
            [1, 1, 1], [1, -1, 1],
        ], dtype=np.float32)

        aabb = aabb_size * aabb
        p.add_lines(aabb, width=3)

        p.add_points(points, render_points_as_spheres=True, point_size=10.0)
        add_camera_frustum(p, pv_cam2world, pv_intr, size=0.4, line_width=2, look_vector_length=far)
        add_coordinate_system(p, pv_cam2world, scale=0.4)
    p.show()


def tests():
    ident = CVtoGL.dot(GLtoCV)
    assert np.allclose(ident, np.eye(4)), 'Matrix must be identity'


if __name__ == '__main__':
    # Run some simple tests to ensure consistency
    tests()

    # CONVENTIONS
    #
    # Camera convention in transforms.json file generated by ns-process-data: OpenGL
    # VERY CONFUSING as camera model in transforms.json is specified as OPEN_CV

    # Camera convention in own dataset (extrinsics.npy): OpenCV
    # Camera convention in nerfstudio: OpenGL
    # Camera convention in sdfstudio: OpenCV

    # In case, an OpenGL error is thrown, set the following variable
    # export MESA_LOADER_DRIVER_OVERRIDE=i965

    # Example usage with nerfstudio (transforms.json) data
    # Default format: OpenGL

    '''
    extr, intr = read_transformation_nerfstudio('../data/head_38/transforms.json')
    for ext in extr:
        ext[:3,3] *= 0.3

        ext[0,3] += 0.4
        ext[1,3] += 0.4
        ext[2,3] += 2.3
    plot(extr, intr, 1.4, 4.0, 1.0, CameraCoordinateConvention.OPEN_GL)
    '''

    # Example usage with own dataset in OpenCV format
    extr, intr = read_transformation_npy('../data/head_38/original_extrinsics.npy',
                                         '../data/head_38/original_intrinsics.npy')
    for i in range(extr.shape[0]):
        extr[i, :, :] = extr[i, :, :].dot(CVtoGL)
    plot(extr, intr, 0.5, 2.8, 1.0, CameraCoordinateConvention.OPEN_GL)